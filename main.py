from dataclasses import dataclass

import numpy as np
from matplotlib import pyplot as plt


def bring_to_interval(x, around):
    while x < around - np.pi:
        x += 2 * np.pi

    while x > around + np.pi:
        x -= 2 * np.pi

    return x


NOT_SEEN_COLOR = "whitesmoke"

MIN_PIXELS_PER_METER = 5


@dataclass
class Camera:
    x: float
    y: float
    orientation: float
    fov: float
    resolution_horizontal: float
    color: str

    def has_point_in_fov(self, px, py):
        orientation = np.deg2rad(self.orientation)
        camera_to_point_angle = bring_to_interval(
            np.arctan2(py - self.y, px - self.x), orientation
        )

        half_fov = np.deg2rad(self.fov / 2)

        return (
            bring_to_interval(orientation - half_fov, orientation)
            <= camera_to_point_angle
            and bring_to_interval(orientation + half_fov, orientation)
            >= camera_to_point_angle
        )

    def compute_information(self, px, py):
        """
        Amount of information at a certain point depends on:
        - camera resolution
        - chord length

        pixels/meter = resolution/distance

        Below code assumes FOV < 180
        """
        camera_to_point_angle = np.arctan2(py - self.y, px - self.x)
        point_angle_in_camera_frame = bring_to_interval(
            np.deg2rad(self.orientation) - camera_to_point_angle, 0
        )
        distance = np.linalg.norm(np.array([self.x, self.y]) - np.array([px, py]))
        chord_distance = distance * np.cos(point_angle_in_camera_frame)

        half_fov = np.deg2rad(self.fov / 2)
        radius = chord_distance / np.cos(half_fov)

        chord_length = 2 * np.sqrt(radius**2 - chord_distance**2)

        if chord_length == 0:
            return 1.0

        pix_per_m = self.resolution_horizontal / chord_length

        if pix_per_m >= self.resolution_horizontal:
            return 1.0

        if pix_per_m <= MIN_PIXELS_PER_METER:
            return 0.0

        return (pix_per_m - MIN_PIXELS_PER_METER) / (
            self.resolution_horizontal - MIN_PIXELS_PER_METER
        )

    def get_color(self, px, py):

        if not self.has_point_in_fov(px, py):
            return None

        return self.color + [self.compute_information(px, py)]


def combine_rgba_list(colors):
    # Code generated by ChatGPT and cleaned for our purposes
    def split_rgb_a(color):
        return color[:3], color[-1]

    # Start with the first color as the base
    rgb, a = split_rgb_a(colors[0])

    # Iterate through the rest of the colors and blend them
    for color in colors[1:]:
        rgb2, a2 = split_rgb_a(color)

        # Calculate the new alpha
        a_new = a + a2 * (1 - a)

        if a_new == 0:
            rgb_new = np.zeros((3,))
        else:
            # Blend the RGB channels
            rgb_new = (rgb * a + rgb2 * a2 * (1 - a)) / a_new

        # Update the current color to the new blended color
        rgb = rgb_new
        a = a_new

    return list(rgb) + [a]


def main():
    cameras = [
        Camera(0, 0.5, 90, 30, 1200, [0, 0, 1]),
        Camera(0, 0.5, 115, 30, 1200, [1, 0.3, 0.2]),
        Camera(0, 0.5, 65, 30, 1200, [1, 0.3, 0.2]),
        Camera(0, -2, -90, 120, 1200, [0, 1, 0]),
        Camera(0.9, 0, 0, 170, 1200, [1, 0.5, 0]),
        Camera(-0.9, 0, 180, 170, 1200, [1, 0.5, 0]),
    ]

    resolution = 0.3
    size = 50

    plt.axis("equal")

    r = np.arange(-size, size, resolution)

    colors_to_plot = []
    xs = []
    ys = []

    for x in r:
        for y in r:
            colors = [c.get_color(x, y) for c in cameras]
            non_empty_colors = [np.array(c) for c in colors if c is not None]
            color = (
                combine_rgba_list(non_empty_colors)
                if non_empty_colors
                else NOT_SEEN_COLOR
            )
            colors_to_plot.append(color)
            xs.append(x)
            ys.append(y)

    plt.scatter(xs, ys, color=colors_to_plot)
    plt.show()


if __name__ == "__main__":
    main()
